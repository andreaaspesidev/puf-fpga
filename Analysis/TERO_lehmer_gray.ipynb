{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from logs\n",
    "Each of the provided logs contains frequencies for each of the 1280 tero-instances, for 100 pufs (100 different board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frequencies(csv_file, counter_bits):\n",
    "    data = pd.read_csv(csv_file, sep=',', skiprows=1, names=[\"BoardNumber\",\"DataSent\", \"#Sent\", \"DataReceived\", \"#Received\"])\n",
    "    responsesRaw = np.array(data['DataReceived'])\n",
    "    responses = []\n",
    "    for responseRaw in responsesRaw:\n",
    "        response = []\n",
    "        for i in range(0, len(responseRaw), int(counter_bits/4)):\n",
    "            response.append(int(responseRaw[i:i+int(counter_bits/4)], 16))\n",
    "        responses.append(response)\n",
    "    responses = np.array(responses)\n",
    "    return np.transpose(responses) # for each row, an instance of tero. for each column, the value in that fpga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1 = extract_frequencies(\"TERO/log_20161008U235656_Small_ChosenRepetition_ChosenTime_22.0C.csv\", 32)\n",
    "freqs2 = extract_frequencies(\"TERO/log_20161009U002207_Small_ChosenRepetition_ChosenTime_22.0C.csv\", 32)\n",
    "freqs3 = extract_frequencies(\"TERO/log_20161009U023930_Small_ChosenRepetition_ChosenTime_-0.0C.csv\", 32)\n",
    "freqs4 = extract_frequencies(\"TERO/log_20161009U110717_Small_ChosenRepetition_ChosenTime_44.1C.csv\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 100)\n",
      "[[  71870  239361  165805 ...  126003   96193   72745]\n",
      " [  61075 1131202  936723 ...   63300  122902  123455]\n",
      " [  68815   93162  373604 ...   43073   73202  447935]\n",
      " ...\n",
      " [  85216  104602   91431 ...  142617  219258  164340]\n",
      " [ 163790   66403  118687 ...  133235  124278  148629]\n",
      " [ 143384  118096   52582 ...  194886   83166  447925]]\n"
     ]
    }
   ],
   "source": [
    "print(freqs1.shape)\n",
    "print(freqs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group frequencies in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n",
    "\n",
    "[0] 0 4 8 12 16\n",
    "[1] 1 5 9 13 17\n",
    "\n",
    "[0] 0 8 16  x 160\n",
    "[1] 1 9 17\n",
    "[2] 2 10 18\n",
    "[3] 3 ...\n",
    "[4] 4 12 20\n",
    "...\n",
    "[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_frequencies(freqs):\n",
    "    # Based on the assumption we have 8 different cell types, we group each type in the right column\n",
    "    NUM_INSTANCES = freqs.shape[0]  # 1280\n",
    "    NUM_FPGA = freqs.shape[1]   # 100\n",
    "    NUM_TYPES = 8\n",
    "    BATCH_SIZE = 16\n",
    "    batchArray = np.zeros((int(NUM_INSTANCES/NUM_TYPES),NUM_TYPES,NUM_FPGA))\n",
    "    for fpga in range(0, NUM_FPGA):\n",
    "        for instance_type in range(0, NUM_TYPES):\n",
    "            batchArray[:,instance_type,fpga] = freqs[instance_type::NUM_TYPES,fpga] # from the starting index, we sample every 8 elements\n",
    "    # batcharray: 160x8x100\n",
    "    BATCH_COLUMNS = int(NUM_INSTANCES/BATCH_SIZE)   # 80\n",
    "    batchResponse = np.zeros((BATCH_SIZE,BATCH_COLUMNS,NUM_FPGA))\n",
    "    for fpga in range(0, NUM_FPGA):\n",
    "        fpgaBatch = np.zeros((BATCH_SIZE, BATCH_COLUMNS))\n",
    "        col = 0\n",
    "        for instance_type in range(0,NUM_TYPES):\n",
    "            # get old column\n",
    "            current_col = batchArray[:,instance_type,fpga]\n",
    "            # create 10 new columns\n",
    "            for index in range(0, len(current_col), BATCH_SIZE):\n",
    "                fpgaBatch[:,col] = current_col[index:index+BATCH_SIZE]\n",
    "                col += 1\n",
    "            # continue for each of the 8 columns (8x10 = 80 columns)\n",
    "        # set the new batch\n",
    "        batchResponse[:,:,fpga] = fpgaBatch[:,:]\n",
    "    return batchResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched1 = group_frequencies(freqs1)\n",
    "batched2 = group_frequencies(freqs2)\n",
    "batched3 = group_frequencies(freqs3)\n",
    "batched4 = group_frequencies(freqs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71870., 132424., 128502.,  87462.,  73009., 107253.,  62552.,\n",
       "       185180.,  92504., 122187.,  83289., 131451., 123793., 607617.,\n",
       "       505165., 101321.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched1[:,0,0] # first batch, first fpga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lehmer-Gray Encoding\n",
    "Sorting the frequencies using Lehmer encoding.  \n",
    "For each frequency $ f_i $, we generate $ s_i = |\\{f_j | f_j < f_i \\wedge j > i \\}| $. The nice property is that if a single frequency swap occurs, the $ s_i $ coefficient only changes +-1.\n",
    "Then these numbers are Gray-encoded, in order that for each +-1 in the $ s_i $ we have just one bit of change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lehmer_encode(batch):\n",
    "    n = len(batch)\n",
    "    lehmanEncoded = np.zeros(n-1, dtype=np.int)\n",
    "    for i in range(n-2, -1, -1):\n",
    "        lehmanEncoded[i] = np.sum(batch[i+1:n] < batch[i])\n",
    "    return lehmanEncoded\n",
    "\n",
    "def gray_encode(s):\n",
    "    # Gray encode each coefficient\n",
    "    return [s[i] ^ (s[i] >> 1) for i in range(0, len(s))]\n",
    "\n",
    "def num_to_binary(n, n_bits):\n",
    "    out = np.zeros(n_bits, dtype=np.int)\n",
    "    i = n_bits-1\n",
    "    while(n > 0):\n",
    "        if n >= pow(2,i):\n",
    "            n = n - pow(2,i)\n",
    "            out[i] = 1\n",
    "        i = i - 1\n",
    "    return out\n",
    "\n",
    "def compress_encode(g, batch_len):\n",
    "    if batch_len == 16:\n",
    "        # encode gray values\n",
    "        gray = np.zeros(7,dtype=np.int)\n",
    "        gray[6] = g[14] + pow(2,1)*g[13] + pow(2,3)*g[12] + pow(2,5)*g[11]\n",
    "        gray[5] = g[10] + pow(2,3)*g[9] + pow(2,6) * (3 & g[8])\n",
    "        gray[4] = (4 & g[8])/pow(2,2) + 2*g[7] + pow(2,5) * (7 & g[6])\n",
    "        gray[3] = (8 & g[6])/pow(2,3) + 2*g[5] + pow(2,5) * (7 & g[4])\n",
    "        gray[2] = (8 & g[4])/pow(2,3) + 2*g[3] + pow(2,5) * (7 & g[2])\n",
    "        gray[1] = (8 & g[2])/pow(2,3) + 2*g[1] + pow(2,5) * (7 & g[0])\n",
    "        gray[0] = (1 & g[0])\n",
    "        # convert to binary\n",
    "        tmp = np.zeros((7,8))\n",
    "        for i in range(0,7):\n",
    "            tmp[i,:] = num_to_binary(gray[i], 8)\n",
    "        # concatenate in a single array\n",
    "        return np.concatenate([[tmp[0,0]], tmp[1,:], tmp[2,:], tmp[3,:], tmp[4,:], tmp[5,:], tmp[6,:]], axis=0)\n",
    "\n",
    "def lehmer_gray_encode_batches(batched):\n",
    "    BATCH_SIZE = batched.shape[0]   #16\n",
    "    NUM_BATCHES = batched.shape[1]  #80\n",
    "    NUM_FPGA = batched.shape[2]     #100\n",
    "    BITS_PER_BATCH = 49\n",
    "    out = np.zeros((BITS_PER_BATCH, NUM_BATCHES, NUM_FPGA), dtype=np.int)\n",
    "    for curr_fpga in range(0,NUM_FPGA):\n",
    "        for curr_batch in range(0, NUM_BATCHES):\n",
    "            le = lehmer_encode(batched[:,curr_batch,curr_fpga])\n",
    "            ge = gray_encode(le)\n",
    "            out[:,curr_batch, curr_fpga] = compress_encode(ge, BATCH_SIZE)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    lehmer_gray_encode_batches(batched1),\n",
    "    lehmer_gray_encode_batches(batched2),\n",
    "    lehmer_gray_encode_batches(batched3),\n",
    "    lehmer_gray_encode_batches(batched4)\n",
    "], dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 49, 80, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniformity\n",
    "The uniformity metric (also called randomness by Yu et al. in [53])\n",
    "determines how uniform the proportion of 0â€² ð‘  and 1â€² ð‘  are in the PUF\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uniformity(response):\n",
    "    return np.sum([response[i] for i in range(0, len(response))]) / len(response)\n",
    "\n",
    "def worst_uniformity(data):\n",
    "    max = 0.5   # ideal value\n",
    "    for puf_num in range(0, data.shape[3]):\n",
    "        for exp_num in range(0, data.shape[0]):\n",
    "            for batch_num in range(0, data.shape[2]):\n",
    "                u = calc_uniformity(data[exp_num,:,batch_num,puf_num])\n",
    "                if np.abs(u - 0.5) > np.abs(max - 0.5):\n",
    "                    max = u\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20408163265306123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_uniformity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reliability\n",
    "It determines how efficiently a PUF can generate the same response\n",
    "at different operating conditions (ambient temperatures or supply volt-\n",
    "ages) over a period of time for a given challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(arr1, arr2): \n",
    "    distance = 0\n",
    "    L = len(arr1)\n",
    "    for i in range(L):\n",
    "        if arr1[i] != arr2[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "\n",
    "def hd_intra(puf_responses):\n",
    "    # 4x49\n",
    "    return np.sum([\n",
    "        hamming_distance(puf_responses[0,:], puf_responses[exp_num,:]) / puf_responses.shape[1]\n",
    "        for exp_num in range(1, puf_responses.shape[0])]) / puf_responses.shape[0]\n",
    "    \n",
    "def reliability(puf_responses):\n",
    "    return 1 - hd_intra(puf_responses)\n",
    "\n",
    "def stat_reliability(data):\n",
    "    min = 1 # ideal value\n",
    "    max = 0\n",
    "    sum = 0\n",
    "    for puf_num in range(0, data.shape[3]):\n",
    "        for batch_num in range(0, data.shape[2]):\n",
    "            r = reliability(data[:,:,batch_num,puf_num])\n",
    "            if r < min:\n",
    "                min = r\n",
    "            if r > max:\n",
    "                max = r\n",
    "            sum += r\n",
    "    return min, max, sum / (data.shape[3] * data.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8163265306122449, 1.0, 0.9410669642857231)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_reliability(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniqueness\n",
    "It measures the variation of responses obtained from different chips\n",
    "for the same set of challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uniqueness(data):\n",
    "    num_bits = data.shape[0]\n",
    "    num_devices = data.shape[1]\n",
    "    return 2/(num_devices*(num_devices-1)) * np.sum([\n",
    "        np.sum([\n",
    "            hamming_distance(data[:,i], data[:,j])/num_bits\n",
    "            for j in range(i, num_devices)])  \n",
    "        for i in range(0, num_devices-2)])\n",
    "\n",
    "def worst_uniqueness(data):\n",
    "    n_esperiments = data.shape[0]\n",
    "    max = 0.5   # ideal value\n",
    "    for exp_num in range(0, n_esperiments):\n",
    "        for batch_num in range(0, data.shape[2]):\n",
    "            u = calc_uniqueness(data[exp_num,:,batch_num,:])\n",
    "            if np.abs(u - 0.5) > np.abs(max - 0.5):\n",
    "                max = u\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46561945990517417"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_uniqueness(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_array_to_string(arr):\n",
    "    response_char = ''\n",
    "    for i in range(0, len(arr)):\n",
    "        response_char = response_char + ('1' if arr[i] else '0')\n",
    "    return response_char  \n",
    "\n",
    "def print_ids_per_fpga(data):\n",
    "    num_batches = data.shape[1] #80\n",
    "    out = []\n",
    "    for curr_batch in range(0, num_batches):\n",
    "        out.append(bit_array_to_string(data[:,curr_batch]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1101111000010010100110100010100000001101011110110',\n",
       " '0110000000001111001011011101101011101110011010011',\n",
       " '1000101001010010100110111101101001111110111101100',\n",
       " '1001101100001010001110100010001011110001111001010',\n",
       " '0001110000110010100010100001001011101001001010010',\n",
       " '0000000100000001100010101011001100100001011001011',\n",
       " '1111001100010010101100100010000100111011111010010',\n",
       " '0101010000110010100110001001100111001010110000110',\n",
       " '1001111101001011100011011000100010101111101001010',\n",
       " '1010011100001110101000111011101011100000011111100']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print all the first 10 ids of the first board at 20Â°C\n",
    "print_ids_per_fpga(data[0,:,:,0])[0:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
