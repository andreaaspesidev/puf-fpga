{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from logs\n",
    "Each of the provided logs contains frequencies for each of the 1280 tero-instances, for 100 pufs (100 different board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frequencies(csv_file, counter_bits):\n",
    "    data = pd.read_csv(csv_file, sep=',', skiprows=1, names=[\"BoardNumber\",\"DataSent\", \"#Sent\", \"DataReceived\", \"#Received\"])\n",
    "    responsesRaw = np.array(data['DataReceived'])\n",
    "    responses = []\n",
    "    for responseRaw in responsesRaw:\n",
    "        response = []\n",
    "        for i in range(0, len(responseRaw), int(counter_bits/4)):\n",
    "            response.append(int(responseRaw[i:i+int(counter_bits/4)], 16))\n",
    "        responses.append(response)\n",
    "    responses = np.array(responses)\n",
    "    return np.transpose(responses) # for each row, an instance of tero. for each column, the value in that fpga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1 = extract_frequencies(\"TERO/log_20161008U235656_Small_ChosenRepetition_ChosenTime_22.0C.csv\", 32)\n",
    "freqs2 = extract_frequencies(\"TERO/log_20161009U002207_Small_ChosenRepetition_ChosenTime_22.0C.csv\", 32)\n",
    "freqs3 = extract_frequencies(\"TERO/log_20161009U023930_Small_ChosenRepetition_ChosenTime_-0.0C.csv\", 32)\n",
    "freqs4 = extract_frequencies(\"TERO/log_20161009U110717_Small_ChosenRepetition_ChosenTime_44.1C.csv\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 100)\n",
      "[[  71870  239361  165805 ...  126003   96193   72745]\n",
      " [  61075 1131202  936723 ...   63300  122902  123455]\n",
      " [  68815   93162  373604 ...   43073   73202  447935]\n",
      " ...\n",
      " [  85216  104602   91431 ...  142617  219258  164340]\n",
      " [ 163790   66403  118687 ...  133235  124278  148629]\n",
      " [ 143384  118096   52582 ...  194886   83166  447925]]\n"
     ]
    }
   ],
   "source": [
    "print(freqs1.shape)\n",
    "print(freqs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group frequencies in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n",
    "\n",
    "[0] 0 4 8 12 16\n",
    "[1] 1 5 9 13 17\n",
    "\n",
    "[0] 0 8 16  x 160\n",
    "[1] 1 9 17\n",
    "[2] 2 10 18\n",
    "[3] 3 ...\n",
    "[4] 4 12 20\n",
    "...\n",
    "[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_frequencies(freqs):\n",
    "    # Based on the assumption we have 8 different cell types, we group each type in the right column\n",
    "    NUM_INSTANCES = freqs.shape[0]  # 1280\n",
    "    NUM_FPGA = freqs.shape[1]   # 100\n",
    "    NUM_TYPES = 8\n",
    "    BATCH_SIZE = 16\n",
    "    batchArray = np.zeros((int(NUM_INSTANCES/NUM_TYPES),NUM_TYPES,NUM_FPGA))\n",
    "    for fpga in range(0, NUM_FPGA):\n",
    "        for instance_type in range(0, NUM_TYPES):\n",
    "            batchArray[:,instance_type,fpga] = freqs[instance_type::NUM_TYPES,fpga] # from the starting index, we sample every 8 elements\n",
    "    # batcharray: 160x8x100\n",
    "    BATCH_COLUMNS = int(NUM_INSTANCES/BATCH_SIZE)   # 80\n",
    "    batchResponse = np.zeros((BATCH_SIZE,BATCH_COLUMNS,NUM_FPGA))\n",
    "    for fpga in range(0, NUM_FPGA):\n",
    "        fpgaBatch = np.zeros((BATCH_SIZE, BATCH_COLUMNS))\n",
    "        col = 0\n",
    "        for instance_type in range(0,NUM_TYPES):\n",
    "            # get old column\n",
    "            current_col = batchArray[:,instance_type,fpga]\n",
    "            # create 10 new columns\n",
    "            for index in range(0, len(current_col), BATCH_SIZE):\n",
    "                fpgaBatch[:,col] = current_col[index:index+BATCH_SIZE]\n",
    "                col += 1\n",
    "            # continue for each of the 8 columns (8x10 = 80 columns)\n",
    "        # set the new batch\n",
    "        batchResponse[:,:,fpga] = fpgaBatch[:,:]\n",
    "    return batchResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched1 = group_frequencies(freqs1)\n",
    "batched2 = group_frequencies(freqs2)\n",
    "batched3 = group_frequencies(freqs3)\n",
    "batched4 = group_frequencies(freqs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 80, 100)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched1[:,0,0] # first batch, first fpga\n",
    "batched1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Comp Algorithm\n",
    "Choosing 2 frequencies for each batch, the response is given by comparing them:\n",
    "\n",
    "* Choose 0 < i < BATCH_SIZE\n",
    "* Choose 0 < j < BATCH_SIZE, i ~= j\n",
    "* If f(i) > f(j) => res = 1, else => res = 0\n",
    "\n",
    "In this way 1 bit for each batch is extracted (in our case 80 bits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_2comp_chosen_i_j (i,j,puf_data):\n",
    "\n",
    "    NUM_BATCHES = puf_data.shape[1]\n",
    "    NUM_FPGA = puf_data.shape[2]\n",
    "\n",
    "    response = np.zeros((NUM_BATCHES,NUM_FPGA))\n",
    "    for currFpga in range (1,NUM_FPGA): #num of fpga\n",
    "        for currBatch in range (1,NUM_BATCHES): #num of batches\n",
    "            if i == j :\n",
    "                response[currBatch,currFpga] = 0\n",
    "            else:\n",
    "                response[currBatch,currFpga] = 1 if puf_data[i,currBatch,currFpga] > puf_data[j,currBatch,currFpga] else 0\n",
    "    \n",
    "    return response # (80 bit, 100 fpga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 100)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_2comp_chosen_i_j (1,2,batched1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_array (experiment):\n",
    "    \"\"\" This function takes an experiment (data for a certain temp) and returns all possible 80bits responses (for each i,j combination)\"\"\"\n",
    "    BATCH_SIZE = 16\n",
    "    SINGLE_RESPONSE_BITS = 80\n",
    "    NUM_FPGA = 100\n",
    "    \n",
    "    res_array = np.zeros((SINGLE_RESPONSE_BITS,BATCH_SIZE*(BATCH_SIZE-1), NUM_FPGA)) #80,256,100\n",
    "    #res_array = np.zeros((BATCH_SIZE*BATCH_SIZE,SINGLE_RESPONSE_BITS, NUM_FPGA)) #256,80,100\n",
    "    curr_ij_couple = 0\n",
    "\n",
    "    for i_index in range(0, BATCH_SIZE):\n",
    "        for j_index in range (0,BATCH_SIZE):\n",
    "            if i_index != j_index :\n",
    "                res_array[:,curr_ij_couple,:] = alg_2comp_chosen_i_j(i_index,j_index,experiment)\n",
    "                curr_ij_couple += 1\n",
    "    \n",
    "    return res_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    get_res_array(batched1),\n",
    "    get_res_array(batched2),\n",
    "    get_res_array(batched3),\n",
    "    get_res_array(batched4)\n",
    "], dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 80, 256, 100)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 256)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[0,:,0,1])\n",
    "data[0,:,:,1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniformity\n",
    "The uniformity metric (also called randomness by Yu et al. in [53])\n",
    "determines how uniform the proportion of 0â€² ð‘  and 1â€² ð‘  are in the PUF\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uniformity(response):\n",
    "    return np.sum([response[i] for i in range(0, len(response))]) / len(response)\n",
    "\n",
    "def worst_uniformity(data):\n",
    "    max = 0.5   # ideal value\n",
    "    for puf_num in range(0, data.shape[3]):\n",
    "        for exp_num in range(0, data.shape[0]):\n",
    "            for batch_num in range(0, data.shape[2]):\n",
    "                u = calc_uniformity(data[exp_num,:,batch_num,puf_num])\n",
    "                if np.abs(u - 0.5) > np.abs(max - 0.5):\n",
    "                    max = u\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_uniformity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reliability\n",
    "It determines how efficiently a PUF can generate the same response\n",
    "at different operating conditions (ambient temperatures or supply volt-\n",
    "ages) over a period of time for a given challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(arr1, arr2): \n",
    "    distance = 0\n",
    "    L = len(arr1)\n",
    "    for i in range(L):\n",
    "        if arr1[i] != arr2[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "\n",
    "def hd_intra(puf_responses):\n",
    "    return np.sum([\n",
    "        hamming_distance(puf_responses[0,:], puf_responses[exp_num,:]) / len(puf_responses[0,:])\n",
    "        for exp_num in range(1, len(puf_responses))]) / len(puf_responses[0,:])\n",
    "    \n",
    "def reliability(puf_responses):\n",
    "    return 1 - hd_intra(puf_responses)\n",
    "\n",
    "def worst_reliability(data):\n",
    "    min = 1 # ideal value\n",
    "    for puf_num in range(0, data.shape[3]):\n",
    "        for batch_num in range(0, data.shape[2]):\n",
    "            r = reliability(data[:,:,batch_num,puf_num])\n",
    "            if r < min:\n",
    "                min = r\n",
    "    return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995625"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_reliability(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_try1 = np.array([[1,2,3],[4,5,6]])\n",
    "arr_try2 = np.array([[7,8,9],[10,11,12]])\n",
    "arr_try3 = np.array([[13,14,15],[16,17,18]])\n",
    "\n",
    "arr_3d = np.array([arr_try1, arr_try2,arr_try3])\n",
    "\n",
    "arr_3d[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniqueness\n",
    "It measures the variation of responses obtained from different chips\n",
    "for the same set of challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uniqueness(data):\n",
    "    num_bits = data.shape[0]\n",
    "    num_devices = data.shape[1]\n",
    "    return 2/(num_devices*(num_devices-1)) * np.sum([\n",
    "        np.sum([\n",
    "            hamming_distance(data[:,i], data[:,j])/num_bits\n",
    "            for j in range(i, num_devices)])  \n",
    "        for i in range(0, num_devices-2)])\n",
    "\n",
    "def worst_uniqueness(data):\n",
    "    n_esperiments = data.shape[0]\n",
    "    max = 0.5   # ideal value\n",
    "    for exp_num in range(0, n_esperiments):\n",
    "        for batch_num in range(0, data.shape[2]):\n",
    "            u = calc_uniqueness(data[exp_num,:,batch_num,:])\n",
    "            if np.abs(u - 0.5) > np.abs(max - 0.5):\n",
    "                max = u\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mworst_uniqueness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mworst_uniqueness\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_esperiments):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m---> 15\u001b[0m         u \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_uniqueness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(u \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m=\u001b[39m u\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mcalc_uniqueness\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m num_bits \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m num_devices \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m(num_devices\u001b[38;5;241m*\u001b[39m(num_devices\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum([\n\u001b[1;32m      5\u001b[0m     np\u001b[38;5;241m.\u001b[39msum([\n\u001b[1;32m      6\u001b[0m         hamming_distance(data[:,i], data[:,j])\u001b[38;5;241m/\u001b[39mnum_bits\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, num_devices)])  \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_devices\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)])\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m num_bits \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m num_devices \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m(num_devices\u001b[38;5;241m*\u001b[39m(num_devices\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum([\n\u001b[0;32m----> 5\u001b[0m     np\u001b[38;5;241m.\u001b[39msum([\n\u001b[1;32m      6\u001b[0m         hamming_distance(data[:,i], data[:,j])\u001b[38;5;241m/\u001b[39mnum_bits\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, num_devices)])  \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_devices\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)])\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m num_bits \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m num_devices \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m(num_devices\u001b[38;5;241m*\u001b[39m(num_devices\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum([\n\u001b[1;32m      5\u001b[0m     np\u001b[38;5;241m.\u001b[39msum([\n\u001b[0;32m----> 6\u001b[0m         \u001b[43mhamming_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mnum_bits\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, num_devices)])  \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_devices\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)])\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mhamming_distance\u001b[0;34m(arr1, arr2)\u001b[0m\n\u001b[1;32m      3\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arr1)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43marr1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m arr2[i]:\n\u001b[1;32m      6\u001b[0m         distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distance\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "worst_uniqueness(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_array_to_string(arr):\n",
    "    response_char = ''\n",
    "    for i in range(0, len(arr)):\n",
    "        response_char = response_char + ('1' if arr[i] else '0')\n",
    "    return response_char  \n",
    "\n",
    "def print_ids_per_fpga(data):\n",
    "    num_batches = data.shape[1] #80\n",
    "    out = []\n",
    "    for curr_batch in range(0, num_batches):\n",
    "        out.append(bit_array_to_string(data[:,curr_batch]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1101111000010010100110100010100000001101011110110',\n",
       " '0110000000001111001011011101101011101110011010011',\n",
       " '1000101001010010100110111101101001111110111101100',\n",
       " '1001101100001010001110100010001011110001111001010',\n",
       " '0001110000110010100010100001001011101001001010010',\n",
       " '0000000100000001100010101011001100100001011001011',\n",
       " '1111001100010010101100100010000100111011111010010',\n",
       " '0101010000110010100110001001100111001010110000110',\n",
       " '1001111101001011100011011000100010101111101001010',\n",
       " '1010011100001110101000111011101011100000011111100']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print all the first 10 ids of the first board at 20Â°C\n",
    "print_ids_per_fpga(data[0,:,:,0])[0:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
